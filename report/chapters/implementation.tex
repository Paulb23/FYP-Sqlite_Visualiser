\section{Implementation}
\label{sec:implementation}

Now that we have looked at how the application is designed. In this next section we will go over the tools I used, how I went about implementing the features, and any problems that I came across along the way.   

\subsection{The tools}
\label{subsec:the_tools}

For this particular application I went with Java and JavaFX for the user interface and controllers. This meant right from the get go I had cross platform support. A MVC style architecture and with JDBC open access to SQL database connections. The only major issue was speed, as SQLite is known to be fast, whether my application could keep up with the requests that where being performed. However, as SQLite only allows one writer at a time this was never an issue. The other downside to using Java was not having direct access to the SQLite API through its own interface. But, after looking at the interface everything that I needed was supported through JDBC.

\subsection{The Modules}
\label{subsec:the_modules}

\subsubsection{The view and controllers}
\label{subsubsec:imp_veiw}

As previously mentioned, the architecture is MVC. And we are using JavaFX. JavaFX comes with a whole host of tools for working with the view, and controllers. 
\\\\
Firstly, each view or section can be repersented using a fxml file. The fxml file is heavly based on HTML, including the support for CSS styling. Each file start with a root node, normaly one of the panes. Such as border, anchor, and grid. For this application I stuck with anchor panes, apart from the menu bar which used a border pane. Then folloing the root pane is the items to attached to it. Each item can be given a unique id that allows it to be controlled with via Java and CSS. In addition to this you can include your own Java classes for custon items.
\\\\
Secondly, the controller is a normal Java class set as the controller for a particular fxml file. This can be done in two ways. The way is to inject the controller into the loading process. This allows you to call other code, such as initisiastion before the fxml file is loaded, and keep track of the controller. The second way is to specify the contrller inside the fxml file, and Java will load the controller in when the file is loaded. But you lose all acess to the controller object. Inside the colltroller the annotation @FXML, allows Java to inject the item from the cotrlller into the view, and vise versia. Giving you full controll over the fxml file and object utitlising the items unuqie id. Through my application I use the first method, to allow controlelr sharing, and manual controll over the controller. 
\\\\
The view is made up of four sections, the menu bar, containing the file, edit and other drop downs, including the icons, and tabs. The other three section, represent the left, middle, and right sections of the central pane. This means that any one time I can display three different views. Each of the section have their own fxml file, depending on the situation they may also share a controller. This can be seen below in figure~\ref{fig:view_breakdown}.

\begin{figure}[H]
	\centering
	\includegraphics[scale=0.5]{images/view_breakdown.png}
	\caption{View breakdown}
	\label{fig:view_breakdown}
\end{figure}

I mentioned eariler that the menu bar will never change, and should never change. Using this fact the menu bar controller also doubles up as a 'master' controller. It controls what is currently seen in the other three sections. Loading and freeing up the necessary sections for that tab. 
\\\\
The central pane is a split pane, with two split dividers allowing each sections size to be adjusted on the fly to fit the users needs. If a section is not needed its just a matter of hiding that panes divider bar. 
\\\\
The controllers for each section extend a abstract controller class. The controller class, enforces a model interface object into the constructor, and implements Observer. The model interface allows each controller to separately contact the model, as previously mentioned to collect the data for the view. And by implementing observer we can register our controllers for the signal when the database is updated. Meaning we can collect the updated information as soon as it is ready. Without having to wait, or having a manual refresh button.    

\subsubsection{Model interface}
\label{subsubsec:imp_model_interface}

The model interface is based on a repository design with all the sub modules attached to it. In order for the controller to communitacate with the sub modules they must also first go through the model interface. This design helps keep everything sepertaed and compaact. All of the sub modles attached to the model interface implement their corrosponding interface. Allowing the implementation to change while keeping the same external view. This enables the design to be adapted to other systems other then SQLite. Below figure~\ref{fig:model_interface_design} show the layout of the model interface.

\begin{figure}[H]
	\centering
	\includegraphics[scale=0.3]{images/model_interface_design.png}
	\caption{Model interface}
	\label{fig:model_interface_design}
\end{figure}

Everything is attached to the model interface, apart from the live updater being the exception with a copy of the model. In addition to providing access to the other modules, it has a very small amount of implementation, that is only used when every module is affected. Such as the case of setting up, closing and opening a database, which are all calls to the corresponding method on the modules interfaces. 

\subsubsection{The database}
\label{subsubsec:databse_imp}

The database module is made up of two parts, the interface and the storage. The interface controls access to the storage. Allowing the adding of new database items, retrieving of database items and stepping through the time line of database objects, and complete clearing of database items. Used with setting up and opening a new database, in order to make sure that the items are not mixed up with different files. The items are stored within a arraylist, and a int counter is used to keep track of where in the array we currently are.
\\\\
The storage is made up of database items, that contain a "snapshot" of the current state of the database file. The database item is made of two parts the meta-data, and B-Tree. The meta-data contains all the information in the header, including a few others such as number of tables, file name, and page number. The B-Tree is a custom implementation, holding the various B-Tree pages, as represented in the file. The database items are filled with information via the file parser. Out of all the classes, the database items, are the most used, being sent to the view for displaying, and modified by the various other modules during creation. 

\subsubsection{File watcher}
\label{subsubsec:file_watcher_imp}

In order to workout when the database was updated. I had two options, use SQLites API or watch the file. The API provided by SQLite is on a per connection base meaning that I would only revive signals when my own application sent SQL commands, which are of no use to me, as  I already know when the commands a sent out. This left me with the latter option, watching the file. Since SQLite is a single file, every time the file / database was updated so would the last modified time. In addition to this as SQLite only allows one writer at a time, I would revive a signal every update consistently.  
\\\\
The original implementation utilised Java's WatchService API. However, when I used it, I found it to be hit or miss whether it would register the change. At one point failed to detect any changes. In the end I ended up rolling my own solution, which is a simple while true loop, recording the last modified time, then when the time differs we send out a single to the rest of the application. 
\\\\
Due to the polling nature of this module, it runs inside its own thread, and communicates over an observer patten, that any another class can tune into, providing they implement the Observer interface. The thread could then process the updated databases without stopping or slowing down the user interface and other interactions.

\subsubsection{File parser}
\label{subsubsec:file_parser_imp}

The file parser takes a database file, a database object, and converts the database file into the databse object. Parsing the database, starts with checking the magic number, then the header, before moving onto the pages. The magic number and header information is just reading the first 100 bytes, correctly. For the pages I relied heavily upon recursion.
\\\\
First I would parse the page header, then switch into the method, that dealt with that type of page, who would then call the original method, when it reached a page number.  Each page was represented as a node, with with contents of the node repersented as a cell. The only main issue with this design is the size of the stack on a large database. Below is the psudocode of the algorithm:

\begin{lstlisting}	
public void parseBTree(stream, database) {
	database.getBTree().setRoot(parsePage(stream, 1, 
								database.getPageSize()));
}

public Node parsePage(stream, pageNumber, pageSize) {
	Node node = new Node();
	PageHeader header = parseHeader(stream, pageNumber, pageSize);
	
	BTreeCell cell;
	switch(header.getType()) {
		case (TABLE_BTREE_LEAF_CELL) {
			cell = parseTableBtreeLeafCell(stream, pageNumber, 
											pageSize);
		}
		....
	}
	if (header.getType() == INTERIOR_CELL) {
		node.addChild(parsePage(in, pageHeader.getRightMostPointer(), 
						pageSize));
	}
	node.setData(cell);
	return node;
}

public cell parseTableBtreeLeafCell(InputStream, PageHeader, Node) {
	Cell cell = new Cell();
	
	int cellPointers[] = header.getCellPointers();
	foreach(cellpointer) {
		cell.data = readData();		
		if (cell has pageNumber) {
			node.addChild(parsePage(in, pagenumber, 
						pageSize));
		}
	}
	
	return cell;
}
\end{lstlisting}

During the process of parsing the tree we also need to decode the 'varints' mentioned in section~\ref{subsubsec:sqlite_data_encoding} especially as we needed to count the number of bytes for the record headers. Below shows the psudocode algorithm that I made in order to decrypt them: 

\begin{lstlisting}	
private long[] decodeVarint(stream) {
	long[] value = new long[];
	byte[] varint = new varint[9];
	
	for (i = 0 to 9) {
		varint[i] = stream.readByte();
		if (first bit is not set) {
			break;
		}
	}
	
	if (i == 0) {
		value[0] = 0;
		value[1] = 1;
	} else {
		for (j == 0 to i) {
			varint[j] = (varint[j] << 1);
		}
		value[0] = varint.toLong();
		value[1] = i + 1;
	}
	return value;
}
\end{lstlisting}

The first value returned in the array is the value of the varint, and the second its size. 

\subsubsection{The log}
\label{subsubsec:log_imp}

The log, though the project has under gone many design changes. The original plan was to have the log run on its own without having to relay on other modules, and would retrieve the original SQL commands that were sent to the database. However, as we wwe will see, this proved unattainable, and I had to only record the changes that occure when a comman is sent. While working on the log there were three ways I could have implemented it in addition to my final method.
\\\\
The first technique I looked at utilised SQLites triggers. Triggers execute SQL commands when, a Delete, insert or update is performed on a table, with a optional where clause. Using this \cite{sqlitetriggers} used three separate triggers to long the time, changes before and after, and type of action performed on the table. The last part is one of the reason why I went for another technique. Firstly, I would need to have three triggers per table in the database, so N*3 triggers where N is the number of tables. Secondly, in order to accomplish this, I needed my own table that the changes are stored to, hence the log file in my original design, where I would attach to the database and write to it. lastly, the triggers ment altering the database file, this is something I wanted to avoid as much as possible, as to not impead on the running of the database.  
\\\\
The second solution, was to try and hook into SQLite through its API more specifically the sqlite3\verb|_|trace function. You pass it a callback function, that is called with the SQL commands, at various stages as it passes through the system. Unfortunately for me at the current time the JBDC for SQLite did not support the function that I needed. So I ended up writing a couple C functions that I could then call from Java in order to access the functions. It worked for the most part, apart from that method only calls the callback function for SQL sent from the current application. Which is useless to me as I wanted to see all the changes. 
\\\\
So with two ways down the third way was to write my own extension to SQLite, or download the source code, and modify to suit my needs it. The seemed to be way to far from the original path, and if I used a custom version it means that it would be limited to only my version of SQLite. And as mentioned previously, I wanted to not modify the data if possible, so writing an extension, that would have to be loaded into SQLite and attached to the database, possibly conflicting with any other extensions they might have left me with my final option.
\\\\
The final option, while less sophisticated then the others, works well, although I do not get the original requests. I do end up recording the time, and all changes that happened per command. Since the database storage contains all of the previous versions like a snapshot of the database. when a update comes in I simply compare the new updated database to the last database that passed through the application.
\\\\
In order to compare database though required looping through every data value in both trees and comparing them, not only the data vale, but also the added pages and removal of pages. This could not be detected through any of the other techniques. Clearly looping through every single item in a larger database would quickly become a bottleneck, and slow the application and parsing down. So in order to speed it up, I did two things, firstly hashed the data array, If the hashes matched then we do not have to loop through the data. the second this was to adjusted my B-trees into a modified version of the Merkle Tree patented by \cite{merkletree}. The basic idea behind the merkle tree is that each node in the tree has a hash of its childrens hash, all the way down to the leaf node, who hash is based on the contents. Below figure~\ref{fig:merkle_tree} shows a digram of the merkle tree.

\begin{figure}[H]
	\centering
	\includegraphics[scale=1.0]{images/merkle_tree.png}
	\caption{Node hashes in a  merkle tree \citep{bitcoin}}
	\label{fig:merkle_tree}
\end{figure}

This means we can tell if there is any change in the current section tree just by comparing the nodes hashes without having to loop over them. meaning that we will only loop over the tree at all when a change is seen. otherwise we can skip it. Creating an unnoticeable change unless many nodes are changed at once. The hash for node is calculated off the hash of the data and number of children meaning we will also know if a page has been added or removed. 
\\\\
In addition to this, when it detects an update to the data, it will mark that page as modified, a simple boolean value. and record the store the string value, from the old page and the new page. If instead it was a removal or addition, of data, it will simply store the value, and leave the removed or non-existent value. Something similar happens with added and removed pages. With the addition of pages, the newer page will be marked as changed. Often when this happens a pointer to the new page will also be placed somewhere, so this is also recorded. When a  page is removed, utilising the data from the old tree we can see exactly what was gone and record it, but there is nothing to marked as changed, apart from the pointers in other pages to that page. 

\subsubsection{Live Updater}
\label{subsubsec:live_Updater_imp}

The Live updater has undergone many changes from the start, although its position in the architecture has not changed, it gradually was morphed and shaped by the rest of the application. Originally it stared out as a relatively simple class that would control the parsing of the application. By contacting the database and telling it when to move along the time line, allowing the pausing of live updates. It would also receive the update signal from the file watcher, and parse the file, moving it into the database storage. Basically an extra more controlled, and tailored interface into the database interface linking it to the file parser.
\\\\
Then as time went on I wanted to have additional information into the metadata of the database, tat required running SQL onto the database, else i would have to loop through the entire tree again. So it needed access to the SQL execute, which we will cover in the next section. Then I ran into problems with the log feature, and it was all to easy to stick the log module inside this one. However, this class soon became bloated, as I added new features, since this was the only one that had access to all the needed resources.
\\\\
Rather then stick with it I decided rather then fighting against my designs it would be better to dedicate this as a master module, that would orchestrate the process when an update signal is revived. This allowed me to move the bloat back into their correct modules. And now it does exactly what I said in the beginning, acts as a tailored interface into the database interface, contacts the file parser, SQL executor, and Log modules to control the parsing of the updated database.

\subsubsection{SQL executor}
\label{subsubsec:sql_executor_imp}

The SQL executor manages the JDBC connections to the database, making sure that it connects, closes and commits any changes that are needed onto the database. It interface provides four methods to the other modules, connect, close, perform select, perform update and get database meta-data. Unlike th rest of the modules this was one of the more straight forward and simple to implement.

\subsection{User Interface}
\label{subsec:user_interface_imp}

I mentioned in the last section how the view is put together, but now we have looked at each of the modules in turn. I wanted to go through how each of the different tabs / features are put together. In order to better understand how each module is interacted with. For a rough idea of what the user inter face looks like see section~\ref{subsec:high_user_interface}. The next section~\ref{sec:system_operation} we will look at the design side of things. 
\\\\
The entire user interface is made up of eight fxml files and one css file.  The first fxml file we will look at is the menu bar. The menu bar as previously mentioned acts like the master controller, controlling what is shown in the other sections of the application. At the very top it contains the file, edit and other drops downs, just below them we have have a selection of image buttons. They are short cuts to the selections with the drop downs. In addition to this using the JavaFX key code combination class, I proved keyboard shortcuts to the command such as 'control o' to open a database. The last item on the menu bar controller is the tabs that allow users to select what they want to view. This section of the view, contacts the model for the opening and closing of databases, and the live updater for controlling what happens and when.  
\\\\
The right section unlike the central and left is similar to the menu bar as in it does not change when a new tab is shown. This is also made up of a single fxml file. It holds the SQL executer. As previously mentioned the SQl executor module enables arbitrary SQL commands to be ran on o the database. And as such this section allows the user to type the SQL inside of text area, which are then sent to the SQL executor, if the action was a update the is then printed out in to the return text area. Or an error if one occurred. However, if it was a select the results are printed into a table, with a message into to return text area.
\\\\
The first tab is made up of one fxml file and no left pane. It shows all the meta data about the current database. It is made up of a flow pane, inside of a scroll pane and can adjust to any size, and any amount of information. The information, inside of the is attached to a grid pane, where the left side column, represent the values description or name and the right hand side the value. Each pane represents a section of the meta data. In order to collect the meta data, the controller needs to contact the database interface.
\\\\
The second tab, contains the table view. And is made up of two fxml files that share a controller. The left hand side contains a drop down that lists all the tables in the database and a text area that displays that tables schema. The central section, contains a table that lists all the content within that table. In order to accomplish this it contacts the SQL executor to collect the schema and data.  
\\\\
The third tab again is made up of two fxml files, how more complex. *TODO*
\\\\
The fourth tab contains the log, and is made up of one fxml file. Similar to the meta data tab, in contains a single scroll pane, with a VBox inside. allowing it to contain infinite items. Each item is made up of a Titled pane. where the title is the time and data of the update, and the content the changes that where performed in the update. As it is a titled pane the content can be collapsed hiding needed information from view. To collect the data, it contacts the Log module.
